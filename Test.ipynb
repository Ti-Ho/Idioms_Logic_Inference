{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 测试CUDA是否可用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.__version__)\n",
    "print(\"gpu\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 字符串测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://zaojv.com/4420198.html\"\n",
    "urll = url[0:-5]\n",
    "urlr = url[-5:]\n",
    "print(urll)\n",
    "print(urlr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 测试正则表达式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def delChars(sentence):\n",
    "    \n",
    "    sentence = re.sub(r'^(（)*(\\()*', \"\", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    sentence = re.sub(r'^(\\d+)*(\\.)*(\\))*(）)*(、)*', \"\", sentence)\n",
    "    sentence = re.sub('(\\d+)*([a-zA-Z]+)', \"\", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    sentence = re.sub('(,)+', \"，\", sentence)\n",
    "    return sentence\n",
    "\n",
    "sentence = \"(1) 这些玻璃工ASFJKDSHFH艺品玲珑asdfaadfa剔透,令人爱不释手。\"\n",
    "sentence = delChars(sentence)\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "sentence = \"刁迈彭一面让他起，一面故意做出～的样子，说‘这是怎么好！这是怎么好！叫我怎么对得起死的大哥！’★李宝嘉《官场现形记》第五十一回\"\n",
    "sentence = re.sub('(★.*)+', \"\", sentence)\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 测试循环"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cy = ['爱不释手', '奇葩异卉', '山清水秀', '美不胜收', '望而生畏']\n",
    "for cyi in range(0, len(cy) - 1):\n",
    "    for cyj in range(cyi + 1, len(cy)):\n",
    "        print(str(cyi) + str(cyj))\n",
    "        print(cy[cyi] + \" \" + cy[cyj])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datalist = []\n",
    "cy = ['爱不释手', '奇葩异卉', '山清水秀', '美不胜收', '望而生畏']\n",
    "for cyi in range(0, len(cy) - 1):\n",
    "    for cyj in range(cyi + 1, len(cy)):\n",
    "        data = []\n",
    "        data.append(cy[cyi])\n",
    "        data.append(cy[cyj])\n",
    "        data.append(sentence)\n",
    "#         print(data)\n",
    "        datalist.append(data)\n",
    "cy = ['爱不释手2', '奇葩异卉2', '山清水秀2', '美不胜收2', '望而生畏2']\n",
    "for cyi in range(0, len(cy) - 1):\n",
    "    for cyj in range(cyi + 1, len(cy)):\n",
    "        data = []\n",
    "        data.append(cy[cyi])\n",
    "        data.append(cy[cyj])\n",
    "        data.append(sentence)\n",
    "#         print(data)\n",
    "        datalist.append(data)\n",
    "print(datalist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 测试字符串列表去重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cy_set = set({\"爱不释手奇葩异卉\"})\n",
    "tmp_set = set({\"爱不释手美不胜收\"})\n",
    "# cy_set = cy_set | tmp_set # 并集\n",
    "cy_set = cy_set & tmp_set # 交集\n",
    "print(cy_set)\n",
    "print(cy_set == set())\n",
    "print(len(cy_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_set = set()\n",
    "subdata_i = ['哀兵必胜', '骄兵必败', '有句话叫做骄兵必败，哀兵必胜。虽然我们队赢了这场比赛，但我们不能骄傲，否则下次输的一方一定是我们。']\n",
    "strcat1 = {subdata_i[0] + subdata_i[1]}\n",
    "strcat2 = {subdata_i[1] + subdata_i[0]}\n",
    "print(strcat1)\n",
    "print(strcat2)\n",
    "all_set |= strcat1\n",
    "all_set |= strcat2\n",
    "print(all_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 测试写csv文件\n",
    "pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#任意的多组列表\n",
    "a = [1,2,3]\n",
    "b = [4,5,6]    \n",
    "\n",
    "#字典中的key值即为csv中列名\n",
    "dataframe = pd.DataFrame({'a_name':a,'b_name':b})\n",
    "，,\n",
    "#将DataFrame存储为csv,index表示是否显示行名，default=True\n",
    "dataframe.to_csv(\"test.csv\",index=True,sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "a = [[1, 2, 3],[2, 3, 4],[3, 4, 5]]\n",
    "a1 = pd.DataFrame(a)\n",
    "a1.to_csv('test.csv',mode='a', index=False,header=[\"成语1\", \"成语2\", \"造句\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "#python2可以用file替代open\n",
    "with open(\"test.csv\",\"a\", newline = \"\") as csvfile: \n",
    "    writer = csv.writer(csvfile)\n",
    "\n",
    "    #先写入columns_name\n",
    "    writer.writerow([\"index\",\"a_name\",\"b_name\"])\n",
    "    #写入多行用writerows\n",
    "    writer.writerows([[0,1,3],[1,2,3],[2,3,4]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 测试读csv文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# data = pd.read_csv('DataCrawler/MyData/Data_1.csv')\n",
    "# print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算爬取的总数据量（条）:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"DataCrawler/MyData/Data_.csv\"\n",
    "tot_len = 0\n",
    "for i in range(1, 29):\n",
    "    pathl = filepath[0:-4]\n",
    "    pathr = filepath[-4:]\n",
    "    nowpath = pathl + str(i) + pathr\n",
    "    # print(nowpath)\n",
    "    data = pd.read_csv(nowpath)\n",
    "    tot_len += len(data)\n",
    "    print(data)\n",
    "print(tot_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"1.csv\"\n",
    "data = pd.read_csv(filepath)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 测试清理脏数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subPageData = [['爱不释dsfa', '奇葩异卉', '这些玻璃工艺品玲珑剔透，令人爱不释手。'],['爱不释手', '奇葩异卉', '这些玻璃工艺品玲珑剔透，令人爱不释手。'], ['爱不释手', '山清水秀', '这些玻璃工艺品玲珑剔透，令人爱不释手。'], ['爱不释手', '美不胜收', '这些玻璃工艺品玲珑剔透，令人爱不释手。'], ['爱不释手', '望而生畏', '这些玻璃工艺品玲珑剔透，令人爱不释手。'], ['奇葩异卉', '山清水秀', '这些玻璃工艺品玲珑剔透，令人爱不释手。'], ['奇葩异卉', '美不胜收', '这些玻璃工艺品玲珑剔透，令人爱不释手。'], ['奇葩异卉', '望而生畏', '这些玻璃工艺品玲珑剔透，令人爱不释手。'], ['山清水秀', '美不胜收', '这些玻璃工艺品玲珑剔透，令人爱不释手。'], ['山清水秀', '望而生畏', '这些玻璃工艺品玲珑剔透，令人爱不释手。'], ['美不胜收', '望而生畏', '这些玻璃工艺品玲珑剔透，令人爱不释手。'], ['爱不释手2', '奇葩异卉2', '这些玻璃工艺品玲珑剔透，令人爱不释手。'], ['爱不释手2', '山清水秀2', '这些玻璃工艺品玲珑剔透，令人爱不释手。'], ['爱不释手2', '美不胜收2', '这些玻璃工艺品玲珑剔透，令人爱不释手。'], ['爱不释手2', '望而生畏2', '这些玻璃工艺品玲珑剔透，令人爱不释手。'], ['奇葩异卉2', '山清水秀2', '这些玻璃工艺品玲珑剔透，令人爱不释手。'], ['奇葩异卉2', '美不胜收2', '这些玻璃工艺品玲珑剔透，令人爱不释手。'], ['奇葩异卉2', '望而生畏2', '这些玻璃工艺品玲珑剔透，令人爱不释手。'], ['山清水秀2', '美不胜收2', '这些玻璃工艺品玲珑剔透，令人爱不释手。'], ['山清水秀2', '望而生畏2', '这些玻璃工艺品玲珑剔透，令人爱不释手。'], ['美不胜收2', '望而生畏2', '这些玻璃工艺品玲珑剔透，令人爱不释手。']]\n",
    "datalist = []\n",
    "for subdata_i in subPageData:\n",
    "    if len(subdata_i[0]) < 4 or len(subdata_i[1]) < 4:\n",
    "        continue\n",
    "    datalist.append(subdata_i)\n",
    "print(len(datalist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 使用pandas将csv文件转成xlsx文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def csv_to_xlsx_pd():\n",
    "    csv = pd.read_csv('DataCrawler/MyData/Data_4.csv', encoding='utf-8')\n",
    "    csv.to_excel('1.xlsx', sheet_name='data', index = False, header = None)\n",
    "csv_to_xlsx_pd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 使用第三方库pandas将xlsx文件转csv文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def xlsx_to_csv_pd():\n",
    "    data_xls = pd.read_excel('1.xlsx', index_col=0)\n",
    "    data_xls.to_csv('1.csv', encoding='utf-8')\n",
    "\n",
    "xlsx_to_csv_pd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. 测试json、python dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'阿鼻地狱': {'explanation': '阿鼻梵语的译音，意译为无间”，即痛苦无有间断之意。常用来比喻黑暗的社会和严酷的牢狱。又比喻无法摆脱的极其痛苦的境地。', 'example': '但也有少数意志薄弱的……逐步上当，终至堕入～。★《上饶集中营·炼狱杂记》'}, '阿党比周': {'explanation': '指相互勾结，相互偏袒，结党营私。', 'example': '《论语·卫灵公》众恶之，必察焉；众好之，必察焉”何晏集解引三国魏王肃曰或众～，或其人特立不群，故好恶不可不察也。”'}, '阿党相为': {'explanation': '阿党偏袒、偏私一方。为了谋求私利相互偏袒、包庇。', 'example': '无'}, '阿狗阿猫': {'explanation': '旧时人们常用的小名。引申为任何轻贱的，不值得重视的人或著作。', 'example': '无'}, '阿姑阿翁': {'explanation': '阿名词的前缀。姑丈夫的母亲。翁丈夫的父亲。指公公婆婆。', 'example': '既然如此，你我两个，便学个不痴不聋的～。★《儿女英雄传》二三回'}}\n",
      "<class 'dict'>\n",
      "['阿鼻地狱', '阿党比周', '阿党相为', '阿狗阿猫', '阿姑阿翁']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "idiomDict = {}\n",
    "# 读取test.json中的数据\n",
    "with open('test.json', 'r',encoding=\"utf-8\") as f1:\n",
    "    list1 = f1.readlines()[0]\n",
    "    preData = json.loads(list1)\n",
    "    for data in preData:\n",
    "        word = data[\"word\"]\n",
    "#         print(data[\"explanation\"])\n",
    "#         print(data[\"example\"])\n",
    "        idiomDict[word] = {}\n",
    "        idiomDict[word][\"explanation\"] = data[\"explanation\"]\n",
    "        idiomDict[word][\"example\"] = data[\"example\"]\n",
    "\n",
    "print(idiomDict)\n",
    "print(type(idiomDict))\n",
    "print(list(idiomDict.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. 测试CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 1, 2, 0, 2, 1, 1, 1, 0, 0, 1, 2, 1, 2, 1, 2])\n",
      "tensor([[ 0.4870,  2.0264,  1.9457],\n",
      "        [-0.8106, -0.4189, -0.2331],\n",
      "        [ 0.8117,  0.1031, -0.5369],\n",
      "        [-0.4613, -0.1268, -0.0186],\n",
      "        [ 0.6888,  0.2111,  0.1638],\n",
      "        [ 0.0987,  1.4254,  0.1458],\n",
      "        [ 0.2610,  0.9352,  1.7628],\n",
      "        [-0.6567, -0.1876, -0.4520],\n",
      "        [ 0.2947,  0.2893, -0.6391],\n",
      "        [ 1.2170,  0.7614, -0.4177],\n",
      "        [-0.6920, -0.4242, -0.1227],\n",
      "        [ 1.7133,  0.3522, -0.9335],\n",
      "        [-0.3449, -0.6127, -0.8734],\n",
      "        [ 0.0263, -0.1226, -0.7970],\n",
      "        [ 0.6767,  2.1075, -0.9630],\n",
      "        [-0.2614, -0.3616,  0.8290]], grad_fn=<AddmmBackward>)\n",
      "tensor(1.1381, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "model = nn.Linear(10, 3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "x = torch.randn(16, 10)\n",
    "# print(x)\n",
    "y = torch.randint(0, 3, size=(16,))  # (16, )\n",
    "print(y)\n",
    "logits = model(x)  # (16, 3)\n",
    "print(logits)\n",
    "loss = criterion(logits, y)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 查看训练日志文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.030890</td>\n",
       "      <td>0.472264</td>\n",
       "      <td>0.998396</td>\n",
       "      <td>0.500675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.998747</td>\n",
       "      <td>0.498768</td>\n",
       "      <td>0.989486</td>\n",
       "      <td>0.504147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.991823</td>\n",
       "      <td>0.501361</td>\n",
       "      <td>0.987797</td>\n",
       "      <td>0.506654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  epoch  train_loss  train_acc test_loss  test_acc\n",
       "0     0    1.030890   0.472264  0.998396  0.500675\n",
       "1     1    0.998747   0.498768  0.989486  0.504147\n",
       "2     2    0.991823   0.501361  0.987797  0.506654"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.read_pickle('IdiomBertModel/state_dict/multi_pool_state_dict/df_log.pickle')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:env4bert]",
   "language": "python",
   "name": "conda-env-env4bert-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
